{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cdb22e5-ceae-4486-8f03-3612afb2ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7131d77a-cddb-463b-b67c-8cb2b3903e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "api_key_router = os.getenv(\"OPEN_ROUTER\")\n",
    "\n",
    "os.environ['HTTP_PROXY'] = 'socks5://localhost:1080'\n",
    "os.environ['HTTPS_PROXY'] = 'socks5://localhost:1080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec1cf58-a1a7-40e8-a3b7-63a5f5a82359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import re\n",
    "import asyncio\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Используй ALL_PROXY для SOCKS5\n",
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'socks5://localhost:1080'\n",
    "os.environ['HTTPS_PROXY'] = 'socks5://localhost:1080'\n",
    "CHANNELS_FILE = \"channels_shorts.txt\"\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client_skor = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key_router,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcebb1fb-cdfe-419b-907e-1d2592d4e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key_router,\n",
    "\n",
    ")\n",
    "\n",
    "# client = OpenAI(\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=api_key_router,\n",
    "\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f8f19-1d87-443a-84dd-374dafd63fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Эксперемент № 1 **********\n",
      "google/gemma-3n-e2b-it:free: flights.json: 1\n",
      "google/gemma-3n-e2b-it:free: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "deepseek/deepseek-r1-0528-qwen3-8b:free: flights.json: 4\n",
      "deepseek/deepseek-r1-0528-qwen3-8b:free: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 2\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "mistralai/mistral-7b-instruct:free: flights.json: 9\n",
      "mistralai/mistral-7b-instruct:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "moonshotai/kimi-vl-a3b-thinking:free: flights.json: 3\n",
      "moonshotai/kimi-vl-a3b-thinking:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "google/gemma-3-4b-it:free: flights.json: 4\n",
      "google/gemma-3-4b-it:free: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 2\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "google/gemma-3n-e4b-it:free: flights.json: 2\n",
      "google/gemma-3n-e4b-it:free: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-4b:free: flights.json: 6\n",
      "qwen/qwen3-4b:free: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-8b:free: flights.json: 4\n",
      "qwen/qwen3-8b:free: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "liquid/lfm-3b: flights.json: 1\n",
      "liquid/lfm-3b: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-3.2-3b-instruct: flights.json: 4\n",
      "meta-llama/llama-3.2-3b-instruct: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-3.1-8b-instruct: flights.json: 1\n",
      "meta-llama/llama-3.1-8b-instruct: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "google/gemma-3n-e4b-it: flights.json: 2\n",
      "google/gemma-3n-e4b-it: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-guard-3-8b: flights.json: 1\n",
      "meta-llama/llama-guard-3-8b: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "Ошибка на moonshotai/kimi-vl-a3b-thinking с файлом flights.json: Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Paid model training). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}\n",
      "Ошибка на moonshotai/kimi-vl-a3b-thinking с файлом questsH.json: Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Paid model training). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}\n",
      "________________________________________________________________________________\n",
      "Ошибка на nousresearch/hermes-2-pro-llama-3-8b с файлом flights.json: Expecting value: line 1159 column 1 (char 6369)\n",
      "nousresearch/hermes-2-pro-llama-3-8b: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "mistralai/mistral-7b-instruct: flights.json: 4\n",
      "mistralai/mistral-7b-instruct: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "mistralai/mistral-7b-instruct-v0.3: flights.json: 2\n",
      "mistralai/mistral-7b-instruct-v0.3: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-3-8b-instruct: flights.json: 2\n",
      "meta-llama/llama-3-8b-instruct: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "deepseek/deepseek-r1-distill-llama-8b: flights.json: 2\n",
      "deepseek/deepseek-r1-distill-llama-8b: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "mistralai/ministral-3b: flights.json: 2\n",
      "mistralai/ministral-3b: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "sao10k/l3-lunaris-8b: flights.json: 2\n",
      "sao10k/l3-lunaris-8b: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-8b: flights.json: 3\n",
      "qwen/qwen3-8b: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "qwen/qwen-2.5-7b-instruct: flights.json: 3\n",
      "qwen/qwen-2.5-7b-instruct: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "cohere/command-r7b-12-2024: flights.json: 1\n",
      "cohere/command-r7b-12-2024: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "Ошибка на google/gemini-flash-1.5-8b с файлом flights.json: Error code: 404 - {'error': {'message': 'No endpoints found for google/gemini-flash-1.5-8b.', 'code': 404}, 'user_id': 'user_31E0uFsbVmsxTJl4YRfj3VZwdH4'}\n",
      "Ошибка на google/gemini-flash-1.5-8b с файлом questsH.json: Error code: 404 - {'error': {'message': 'No endpoints found for google/gemini-flash-1.5-8b.', 'code': 404}, 'user_id': 'user_31E0uFsbVmsxTJl4YRfj3VZwdH4'}\n",
      "________________________________________________________________________________\n",
      "nvidia/nemotron-nano-9b-v2: flights.json: 4\n",
      "nvidia/nemotron-nano-9b-v2: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "********** Эксперемент № 2 **********\n",
      "google/gemma-3n-e2b-it:free: flights.json: 1\n",
      "google/gemma-3n-e2b-it:free: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "deepseek/deepseek-r1-0528-qwen3-8b:free: flights.json: 3\n",
      "deepseek/deepseek-r1-0528-qwen3-8b:free: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 2\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "mistralai/mistral-7b-instruct:free: flights.json: 6\n",
      "mistralai/mistral-7b-instruct:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "Ошибка на moonshotai/kimi-vl-a3b-thinking:free с файлом flights.json: Expecting value: line 167 column 1 (char 913)\n",
      "moonshotai/kimi-vl-a3b-thinking:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "google/gemma-3-4b-it:free: flights.json: 2\n",
      "google/gemma-3-4b-it:free: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 3\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "google/gemma-3n-e4b-it:free: flights.json: 2\n",
      "google/gemma-3n-e4b-it:free: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-4b:free: flights.json: 2\n",
      "qwen/qwen3-4b:free: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-8b:free: flights.json: 3\n",
      "qwen/qwen3-8b:free: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "liquid/lfm-3b: flights.json: 1\n",
      "liquid/lfm-3b: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-3.2-3b-instruct: flights.json: 3\n",
      "meta-llama/llama-3.2-3b-instruct: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-3.1-8b-instruct: flights.json: 2\n",
      "meta-llama/llama-3.1-8b-instruct: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "google/gemma-3n-e4b-it: flights.json: 1\n",
      "google/gemma-3n-e4b-it: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-guard-3-8b: flights.json: 1\n",
      "meta-llama/llama-guard-3-8b: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "Ошибка на moonshotai/kimi-vl-a3b-thinking с файлом flights.json: Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Paid model training). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}\n",
      "Ошибка на moonshotai/kimi-vl-a3b-thinking с файлом questsH.json: Error code: 404 - {'error': {'message': 'No endpoints found matching your data policy (Paid model training). Configure: https://openrouter.ai/settings/privacy', 'code': 404}}\n",
      "________________________________________________________________________________\n",
      "Ошибка на nousresearch/hermes-2-pro-llama-3-8b с файлом flights.json: Expecting value: line 3005 column 1 (char 16522)\n",
      "Ошибка на nousresearch/hermes-2-pro-llama-3-8b с файлом questsH.json: Expecting value: line 151 column 1 (char 825)\n",
      "________________________________________________________________________________\n",
      "mistralai/mistral-7b-instruct: flights.json: 8\n",
      "mistralai/mistral-7b-instruct: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "mistralai/mistral-7b-instruct-v0.3: flights.json: 1\n",
      "mistralai/mistral-7b-instruct-v0.3: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-3-8b-instruct: flights.json: 3\n",
      "meta-llama/llama-3-8b-instruct: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "deepseek/deepseek-r1-distill-llama-8b: flights.json: 2\n",
      "deepseek/deepseek-r1-distill-llama-8b: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "mistralai/ministral-3b: flights.json: 2\n",
      "mistralai/ministral-3b: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "sao10k/l3-lunaris-8b: flights.json: 3\n",
      "sao10k/l3-lunaris-8b: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-8b: flights.json: 3\n",
      "qwen/qwen3-8b: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "qwen/qwen-2.5-7b-instruct: flights.json: 5\n",
      "qwen/qwen-2.5-7b-instruct: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "cohere/command-r7b-12-2024: flights.json: 2\n",
      "cohere/command-r7b-12-2024: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "Ошибка на google/gemini-flash-1.5-8b с файлом flights.json: Error code: 404 - {'error': {'message': 'No endpoints found for google/gemini-flash-1.5-8b.', 'code': 404}, 'user_id': 'user_31E0uFsbVmsxTJl4YRfj3VZwdH4'}\n",
      "Ошибка на google/gemini-flash-1.5-8b с файлом questsH.json: Error code: 404 - {'error': {'message': 'No endpoints found for google/gemini-flash-1.5-8b.', 'code': 404}, 'user_id': 'user_31E0uFsbVmsxTJl4YRfj3VZwdH4'}\n",
      "________________________________________________________________________________\n",
      "nvidia/nemotron-nano-9b-v2: flights.json: 6\n",
      "nvidia/nemotron-nano-9b-v2: questsH.json: 5\n",
      "________________________________________________________________________________\n",
      "********** Эксперемент № 3 **********\n",
      "google/gemma-3n-e2b-it:free: flights.json: 1\n",
      "google/gemma-3n-e2b-it:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "deepseek/deepseek-r1-0528-qwen3-8b:free: flights.json: 3\n",
      "deepseek/deepseek-r1-0528-qwen3-8b:free: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 2\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "mistralai/mistral-7b-instruct:free: flights.json: 7\n",
      "mistralai/mistral-7b-instruct:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "moonshotai/kimi-vl-a3b-thinking:free: flights.json: 2\n",
      "moonshotai/kimi-vl-a3b-thinking:free: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "google/gemma-3-4b-it:free: flights.json: 3\n",
      "google/gemma-3-4b-it:free: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 1\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 2\n",
      "________________________________________________________________________________\n",
      "google/gemma-3n-e4b-it:free: flights.json: 2\n",
      "google/gemma-3n-e4b-it:free: questsH.json: 1\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-4b:free: flights.json: 3\n",
      "qwen/qwen3-4b:free: questsH.json: 5\n",
      "________________________________________________________________________________\n",
      "qwen/qwen3-8b:free: flights.json: 1\n",
      "qwen/qwen3-8b:free: questsH.json: 4\n",
      "________________________________________________________________________________\n",
      "liquid/lfm-3b: flights.json: 1\n",
      "liquid/lfm-3b: questsH.json: 3\n",
      "________________________________________________________________________________\n",
      "meta-llama/llama-3.2-3b-instruct: flights.json: 3\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a database analyst. \n",
    "Your task is to analyze the logical data model, data statistics, \n",
    "as well as the structure and statistics of SQL queries.\n",
    "Provide recommendations for modifying the data structure and queries \n",
    "to optimize performance.\n",
    "Respond with a JSON object containing the following fields:\n",
    "- ddl: a new set of DDL statements to modify the table structure\n",
    "- migrations: a set of queries for migrating data\n",
    "- queries: a set of queries with their identifiers that use the new table structure\n",
    "\"\"\"\n",
    "# Папка с JSON-файлами\n",
    "datasets_path = \"datasets\"\n",
    "json_files = [f for f in os.listdir(datasets_path) if f.endswith(\".json\")]\n",
    "\n",
    "llm_list = [\n",
    "    \"google/gemma-3n-e2b-it:free\",\n",
    "    \"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "    \"nousresearch/deephermes-3-llama-3-8b-preview:free\",\n",
    "    \"mistralai/mistral-7b-instruct:free\",\n",
    "    \"moonshotai/kimi-vl-a3b-thinking:free\",\n",
    "    \"google/gemma-3-4b-it:free\",\n",
    "    \"nousresearch/deephermes-3-llama-3-8b-preview:free\",\n",
    "    \"google/gemma-3n-e4b-it:free\",\n",
    "    \"qwen/qwen3-4b:free\",\n",
    "    \"qwen/qwen3-8b:free\",\n",
    "    \"liquid/lfm-3b\",\n",
    "    \"meta-llama/llama-3.2-3b-instruct\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"google/gemma-3n-e4b-it\",\n",
    "    \"meta-llama/llama-guard-3-8b\",\n",
    "    \"moonshotai/kimi-vl-a3b-thinking\",\n",
    "    \"nousresearch/hermes-2-pro-llama-3-8b\",\n",
    "    \"mistralai/mistral-7b-instruct\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.3\",\n",
    "    \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"deepseek/deepseek-r1-distill-llama-8b\",\n",
    "    \"mistralai/ministral-3b\",\n",
    "    \"sao10k/l3-lunaris-8b\",\n",
    "    \"qwen/qwen3-8b\",\n",
    "    \"qwen/qwen-2.5-7b-instruct\",\n",
    "    \"cohere/command-r7b-12-2024\",\n",
    "    \"google/gemini-flash-1.5-8b\",\n",
    "    \"nvidia/nemotron-nano-9b-v2\",\n",
    "    \n",
    "]\n",
    "\n",
    "llm_score = {}\n",
    "\n",
    "def generate_tg_caption(task_input: str, output: str) -> str:\n",
    "    prompt = f\"\"\"You are an evaluator of LLM responses. \n",
    "    Evaluate the response strictly on a 10-point scale (1 = worst, 10 = best), based on correctness and completeness.\n",
    "    \n",
    "    The LLM receives the following input:\n",
    "    - DDL statements for creating tables. The script is split into individual queries for each table.\n",
    "    - A set of queries with statistics on how many times each query was executed.\n",
    "    - A JDBC connection string with login and password to evaluate the actual data.\n",
    "    \n",
    "    The LLM output includes:\n",
    "    - A new set of DDL queries to modify the table structure.\n",
    "    - A set of queries for data migration.\n",
    "    - A set of queries with identifiers that use the new table structure.\n",
    "    \n",
    "    Your task: **return only a single integer from 1 to 10** that represents the overall quality of the LLM response. Do not include any explanation, text, or punctuation.\n",
    "    \n",
    "    Input: {task_input}\n",
    "    LLM Response: {output}\n",
    "    \"\"\"\n",
    "    resp = client_skor.chat.completions.create(\n",
    "        model=\"x-ai/grok-4-fast\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=10,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "def main():\n",
    "    for i in range(5):\n",
    "        print('*'*10, f'Эксперемент № {i+1}','*'*10)\n",
    "        for llm in llm_list:\n",
    "            for file_name in json_files:\n",
    "                file_path = os.path.join(datasets_path, file_name)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    task_input = json.dumps(json.load(f))\n",
    "    \n",
    "                resp = None\n",
    "                # Попытка сначала с system + user\n",
    "                try:\n",
    "                    resp = client.chat.completions.create(\n",
    "                        model=llm,\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": system_prompt},\n",
    "                            {\"role\": \"user\", \"content\": task_input}\n",
    "                        ],\n",
    "                        extra_headers={\n",
    "                            \"HTTP-Referer\": \"http://localhost\",\n",
    "                            \"X-Title\": \"My Test Script\"\n",
    "                        }\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    if \"Developer instruction is not enabled\" in str(e):\n",
    "                        try:\n",
    "                            resp = client.chat.completions.create(\n",
    "                                model=llm,\n",
    "                                temperature=0.0,\n",
    "                                messages=[\n",
    "                                    {\"role\": \"user\", \"content\": f\"{system_prompt}\\n{task_input}\"}\n",
    "                                ],\n",
    "                                extra_headers={\n",
    "                                    \"HTTP-Referer\": \"http://localhost\",\n",
    "                                    \"X-Title\": \"My Test Script\"\n",
    "                                }\n",
    "                            )\n",
    "                        except Exception as inner_e:\n",
    "                            print(f\"Ошибка на {llm} с файлом {file_name}: {inner_e}\")\n",
    "                            continue  # пропускаем этот файл для текущего LLM\n",
    "                    else:\n",
    "                        print(f\"Ошибка на {llm} с файлом {file_name}: {e}\")\n",
    "                        continue  # пропускаем этот файл для текущего LLM\n",
    "    \n",
    "                if resp is None:\n",
    "                    print(f\"Пропущено: {llm} {file_name} (нет ответа)\")\n",
    "                    continue\n",
    "    \n",
    "                output = resp.choices[0].message.content\n",
    "                res = generate_tg_caption(task_input, output)\n",
    "                llm_score.setdefault(i+1, {})  \n",
    "                llm_score[i+1].setdefault(llm, {})  \n",
    "                llm_score[i+1][llm][file_name] = res  \n",
    "                print(f'{llm}: {file_name}: {res}')\n",
    "            print('_'*80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e564d3c-3e29-4ebb-a09c-deb6a6351f50",
   "metadata": {},
   "source": [
    "### Эксперементы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b762466-57b4-4ad5-a645-53ade295421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "google/gemma-3n-e2b-it:free: flights.json: 8\n",
    "google/gemma-3n-e2b-it:free: questsH.json: 4\n",
    "________________________________________________________________________________\n",
    "deepseek/deepseek-r1-0528-qwen3-8b:free: flights.json: 8\n",
    "deepseek/deepseek-r1-0528-qwen3-8b:free: questsH.json: 8\n",
    "________________________________________________________________________________\n",
    "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 7\n",
    "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 8\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ea4ce23-de6c-4a26-8942-e7495951db92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "google/gemma-3n-e2b-it:free: flights.json: 5\n",
    "google/gemma-3n-e2b-it:free: questsH.json: 5\n",
    "________________________________________________________________________________\n",
    "deepseek/deepseek-r1-0528-qwen3-8b:free: flights.json: 8\n",
    "deepseek/deepseek-r1-0528-qwen3-8b:free: questsH.json: 4\n",
    "________________________________________________________________________________\n",
    "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 6\n",
    "nousresearch/deephermes-3-llama-3-8b-preview:free: questsH.json: 9\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e05d0d-e98d-4008-93bf-f4ba0d5793af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "google/gemma-3n-e2b-it:free: flights.json: 6\n",
    "google/gemma-3n-e2b-it:free: questsH.json: 3\n",
    "________________________________________________________________________________\n",
    "deepseek/deepseek-r1-0528-qwen3-8b:free: flights.json: 5\n",
    "deepseek/deepseek-r1-0528-qwen3-8b:free: questsH.json: 8\n",
    "________________________________________________________________________________\n",
    "nousresearch/deephermes-3-llama-3-8b-preview:free: flights.json: 8\n",
    "Ошибка на nousresearch/deephermes-3-llama-3-8b-preview:free с файлом questsH.json: Expecting value: line 805 column 1 (char 4422)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e387893-beeb-4e78-b110-8ffe57898f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3629a-4f4c-4f4d-b6ff-dcefdd9316a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for iteration, llms in llm_score.items():\n",
    "    for llm, files in llms.items():\n",
    "        for file_name, score in files.items():\n",
    "            rows.append({\n",
    "                \"iteration\": iteration,\n",
    "                \"llm\": llm,\n",
    "                \"file_name\": file_name,\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c37a4bc-46f0-4987-a823-5dc04e82984b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experement</th>\n",
       "      <th>name_model</th>\n",
       "      <th>flights.json</th>\n",
       "      <th>questsH.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>google/gemma-3n-e2b-it:free</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>deepseek/deepseek-r1-0528-qwen3-8b:free</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nousresearch/deephermes-3-llama-3-8b-preview:free</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>mistralai/mistral-7b-instruct:free</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>moonshotai/kimi-vl-a3b-thinking:free</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5</td>\n",
       "      <td>qwen/qwen3-8b</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>5</td>\n",
       "      <td>qwen/qwen-2.5-7b-instruct</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5</td>\n",
       "      <td>cohere/command-r7b-12-2024</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>5</td>\n",
       "      <td>google/gemini-flash-1.5-8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5</td>\n",
       "      <td>nvidia/nemotron-nano-9b-v2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     experement                                         name_model  \\\n",
       "0             1                        google/gemma-3n-e2b-it:free   \n",
       "1             1            deepseek/deepseek-r1-0528-qwen3-8b:free   \n",
       "2             1  nousresearch/deephermes-3-llama-3-8b-preview:free   \n",
       "3             1                 mistralai/mistral-7b-instruct:free   \n",
       "4             1               moonshotai/kimi-vl-a3b-thinking:free   \n",
       "..          ...                                                ...   \n",
       "135           5                                      qwen/qwen3-8b   \n",
       "136           5                          qwen/qwen-2.5-7b-instruct   \n",
       "137           5                         cohere/command-r7b-12-2024   \n",
       "138           5                         google/gemini-flash-1.5-8b   \n",
       "139           5                         nvidia/nemotron-nano-9b-v2   \n",
       "\n",
       "     flights.json  questsH.json  \n",
       "0               7             3  \n",
       "1               6             7  \n",
       "2               9             3  \n",
       "3               0             7  \n",
       "4               3             3  \n",
       "..            ...           ...  \n",
       "135             0             7  \n",
       "136             6             8  \n",
       "137             4             3  \n",
       "138             0             0  \n",
       "139             8             9  \n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('models_results_table_grok.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09e21c30-80c1-45ac-9e83-0b7a99dd2027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flights.json</th>\n",
       "      <th>questsH.json</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>google/gemma-3-4b-it:free</th>\n",
       "      <td>8.6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-4b:free</th>\n",
       "      <td>8.6</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nvidia/nemotron-nano-9b-v2</th>\n",
       "      <td>8.2</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquid/lfm-3b</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen-2.5-7b-instruct</th>\n",
       "      <td>7.8</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-8b:free</th>\n",
       "      <td>7.6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/ministral-3b</th>\n",
       "      <td>7.6</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-3.1-8b-instruct</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/mistral-7b-instruct:free</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-r1-0528-qwen3-8b:free</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/mistral-7b-instruct-v0.3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/mistral-7b-instruct</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3n-e4b-it:free</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-8b</th>\n",
       "      <td>6.8</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-3.2-3b-instruct</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-3-8b-instruct</th>\n",
       "      <td>5.8</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nousresearch/deephermes-3-llama-3-8b-preview:free</th>\n",
       "      <td>5.8</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sao10k/l3-lunaris-8b</th>\n",
       "      <td>5.6</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-r1-distill-llama-8b</th>\n",
       "      <td>4.6</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohere/command-r7b-12-2024</th>\n",
       "      <td>4.2</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3n-e4b-it</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonshotai/kimi-vl-a3b-thinking:free</th>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3n-e2b-it:free</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-guard-3-8b</th>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nousresearch/hermes-2-pro-llama-3-8b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-flash-1.5-8b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonshotai/kimi-vl-a3b-thinking</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   flights.json  questsH.json\n",
       "name_model                                                                   \n",
       "google/gemma-3-4b-it:free                                   8.6           8.0\n",
       "qwen/qwen3-4b:free                                          8.6           7.2\n",
       "nvidia/nemotron-nano-9b-v2                                  8.2           8.4\n",
       "liquid/lfm-3b                                               8.0           7.2\n",
       "qwen/qwen-2.5-7b-instruct                                   7.8           7.4\n",
       "qwen/qwen3-8b:free                                          7.6           8.0\n",
       "mistralai/ministral-3b                                      7.6           6.2\n",
       "meta-llama/llama-3.1-8b-instruct                            7.2           6.6\n",
       "mistralai/mistral-7b-instruct:free                          7.2           6.6\n",
       "deepseek/deepseek-r1-0528-qwen3-8b:free                     7.2           6.4\n",
       "mistralai/mistral-7b-instruct-v0.3                          7.2           6.4\n",
       "mistralai/mistral-7b-instruct                               7.2           6.2\n",
       "google/gemma-3n-e4b-it:free                                 7.0           4.6\n",
       "qwen/qwen3-8b                                               6.8           7.8\n",
       "meta-llama/llama-3.2-3b-instruct                            6.4           6.4\n",
       "meta-llama/llama-3-8b-instruct                              5.8           6.4\n",
       "nousresearch/deephermes-3-llama-3-8b-preview:free           5.8           5.9\n",
       "sao10k/l3-lunaris-8b                                        5.6           7.0\n",
       "deepseek/deepseek-r1-distill-llama-8b                       4.6           5.8\n",
       "cohere/command-r7b-12-2024                                  4.2           5.2\n",
       "google/gemma-3n-e4b-it                                      4.0           6.4\n",
       "moonshotai/kimi-vl-a3b-thinking:free                        2.8           2.8\n",
       "google/gemma-3n-e2b-it:free                                 2.6           1.2\n",
       "meta-llama/llama-guard-3-8b                                 2.4           3.4\n",
       "nousresearch/hermes-2-pro-llama-3-8b                        0.0           5.6\n",
       "google/gemini-flash-1.5-8b                                  0.0           0.0\n",
       "moonshotai/kimi-vl-a3b-thinking                             0.0           0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['name_model'])[['flights.json','questsH.json']].mean().sort_values(by=[\"flights.json\", \"questsH.json\"], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b91c370b-952a-4956-aacc-a6c62dff7885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flights.json</th>\n",
       "      <th>questsH.json</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>google/gemma-3-4b-it:free</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/mistral-7b-instruct:free</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-4b:free</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquid/lfm-3b</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nvidia/nemotron-nano-9b-v2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen-2.5-7b-instruct</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-8b</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-8b:free</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-r1-0528-qwen3-8b:free</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-3.1-8b-instruct</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/mistral-7b-instruct</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/ministral-3b</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/mistral-7b-instruct-v0.3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-3.2-3b-instruct</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-3-8b-instruct</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3n-e4b-it:free</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sao10k/l3-lunaris-8b</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nousresearch/deephermes-3-llama-3-8b-preview:free</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohere/command-r7b-12-2024</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-r1-distill-llama-8b</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3n-e4b-it</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonshotai/kimi-vl-a3b-thinking:free</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-guard-3-8b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nousresearch/hermes-2-pro-llama-3-8b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-flash-1.5-8b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-3n-e2b-it:free</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonshotai/kimi-vl-a3b-thinking</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   flights.json  questsH.json\n",
       "name_model                                                                   \n",
       "google/gemma-3-4b-it:free                                   9.0           8.0\n",
       "mistralai/mistral-7b-instruct:free                          9.0           7.0\n",
       "qwen/qwen3-4b:free                                          9.0           7.0\n",
       "liquid/lfm-3b                                               8.0           8.0\n",
       "nvidia/nemotron-nano-9b-v2                                  8.0           8.0\n",
       "qwen/qwen-2.5-7b-instruct                                   8.0           8.0\n",
       "qwen/qwen3-8b                                               8.0           8.0\n",
       "qwen/qwen3-8b:free                                          8.0           8.0\n",
       "deepseek/deepseek-r1-0528-qwen3-8b:free                     8.0           7.0\n",
       "meta-llama/llama-3.1-8b-instruct                            8.0           7.0\n",
       "mistralai/mistral-7b-instruct                               8.0           7.0\n",
       "mistralai/ministral-3b                                      8.0           6.0\n",
       "mistralai/mistral-7b-instruct-v0.3                          8.0           6.0\n",
       "meta-llama/llama-3.2-3b-instruct                            7.0           8.0\n",
       "meta-llama/llama-3-8b-instruct                              7.0           6.0\n",
       "google/gemma-3n-e4b-it:free                                 7.0           4.0\n",
       "sao10k/l3-lunaris-8b                                        6.0           8.0\n",
       "nousresearch/deephermes-3-llama-3-8b-preview:free           6.0           5.5\n",
       "cohere/command-r7b-12-2024                                  4.0           6.0\n",
       "deepseek/deepseek-r1-distill-llama-8b                       4.0           6.0\n",
       "google/gemma-3n-e4b-it                                      4.0           6.0\n",
       "moonshotai/kimi-vl-a3b-thinking:free                        3.0           3.0\n",
       "meta-llama/llama-guard-3-8b                                 1.0           1.0\n",
       "nousresearch/hermes-2-pro-llama-3-8b                        0.0           7.0\n",
       "google/gemini-flash-1.5-8b                                  0.0           0.0\n",
       "google/gemma-3n-e2b-it:free                                 0.0           0.0\n",
       "moonshotai/kimi-vl-a3b-thinking                             0.0           0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['name_model'])[['flights.json','questsH.json']].median().sort_values(by=[\"flights.json\", \"questsH.json\"], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea79910-0715-4a2b-8d60-9eab0fc4459b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c2f97-4eed-4fef-b017-85448fa1d71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b3961-ef83-4407-a592-c3630b16edd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101d8ca-1467-4d2a-acc5-0d9c894f2269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f8d1e-6182-4eb0-b5d6-d46083a41892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923db65-8a67-49d0-9f8f-cd6fd2d92854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a7a27-699c-45aa-a33d-3da90ab57607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d4830-1a0b-4723-b0bb-39da312ae0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dfb2a0-a469-4b0e-86c5-63cf74ea7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ПОДВАл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33143407-71a0-46e9-88b8-99719fa17e79",
   "metadata": {},
   "source": [
    "## Подключение к Trino из Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665908ed-7a93-43af-ba83-709baec536e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trino\n",
    "\n",
    "conn = trino.dbapi.connect(\n",
    "    host='localhost',\n",
    "    port=8000,\n",
    "    user='test',\n",
    "    catalog='flights',\n",
    "    schema='default'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SHOW CATALOGS\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c16e17-74bc-49e1-ad9f-e437744dc67c",
   "metadata": {},
   "source": [
    "## Выполнение DDL из JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6e925-702b-4d99-959c-c3cb187061a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import trino\n",
    "\n",
    "# ---------- Параметры соединения ----------\n",
    "conn = trino.dbapi.connect(\n",
    "    host='localhost',\n",
    "    port=8000,\n",
    "    user='test',\n",
    "    catalog='flights',    # у тебя должен быть catalog flights\n",
    "    schema='public'       # default schema when connecting\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ---------- Утилиты ----------\n",
    "_with_re = re.compile(r'\\s+WITH\\s*\\(\\s*[^)]*\\)\\s*;?$', re.IGNORECASE | re.DOTALL)\n",
    "_create_table_re = re.compile(r'^\\s*CREATE\\s+TABLE\\s+([^\\s(]+)', re.IGNORECASE)\n",
    "\n",
    "def strip_with_clause(statement: str) -> str:\n",
    "    s = statement.strip()\n",
    "    if s.endswith(';'):\n",
    "        s = s[:-1].rstrip()\n",
    "    return _with_re.sub(\"\", s)\n",
    "\n",
    "def parse_fq_name(fq: str):\n",
    "    \"\"\"Разбивает fully-qualified имя (catalog.schema.table or schema.table or table)\"\"\"\n",
    "    parts = fq.split('.')\n",
    "    parts = [p.strip().strip('\"') for p in parts]\n",
    "    if len(parts) == 3:\n",
    "        return parts[0], parts[1], parts[2]\n",
    "    if len(parts) == 2:\n",
    "        return None, parts[0], parts[1]  # no catalog specified\n",
    "    return None, None, parts[0]\n",
    "\n",
    "def ensure_schema_exists(catalog, schema):\n",
    "    \"\"\"Создаёт схему, если её нет. Используем CREATE SCHEMA IF NOT EXISTS, но ловим ошибки.\"\"\"\n",
    "    if not catalog or not schema:\n",
    "        return\n",
    "    try:\n",
    "        cursor.execute(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "        print(f\"Ensured schema: {catalog}.{schema}\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to CREATE SCHEMA IF NOT EXISTS:\", e)\n",
    "        # Попробуем без IF NOT EXISTS (на старых версиях)\n",
    "        try:\n",
    "            cursor.execute(f\"CREATE SCHEMA {catalog}.{schema}\")\n",
    "            print(f\"Created schema: {catalog}.{schema}\")\n",
    "        except Exception as e2:\n",
    "            print(\"CREATE SCHEMA also failed:\", e2)\n",
    "            raise\n",
    "\n",
    "# ---------- Основной цикл: применяем DDL из JSON ----------\n",
    "with open(\"datasets/flights.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    task_input = json.load(f)\n",
    "\n",
    "for ddl_obj in task_input.get(\"ddl\", []):\n",
    "    orig = ddl_obj[\"statement\"]\n",
    "    statement = orig.strip().rstrip(';')\n",
    "    print(\"\\n--- DDL attempt ---\")\n",
    "    print(statement[:200], \"...\" if len(statement) > 200 else \"\")\n",
    "    try:\n",
    "        cursor.execute(statement)\n",
    "        print(\"Executed original DDL successfully.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        print(\"Original DDL failed:\", msg)\n",
    "\n",
    "    # Если ошибка связана с table property (например format) — удаляем WITH(...) и пробуем\n",
    "    try:\n",
    "        cleaned = strip_with_clause(statement)\n",
    "        # перед выполнением cleaned: найдём имя таблицы, и создадим схему, если нужно\n",
    "        m = _create_table_re.search(cleaned)\n",
    "        if m:\n",
    "            fq = m.group(1)\n",
    "            cat, sch, tbl = parse_fq_name(fq)\n",
    "            # Если DDL в JSON указывает полное имя flights.public.flights,\n",
    "            # то cat='flights', sch='public'\n",
    "            # если cat не указан, используем текущее соединение (conn.catalog)\n",
    "            if not cat:\n",
    "                cat = cursor._connection._catalog if hasattr(cursor, '_connection') else None\n",
    "            if sch:\n",
    "                ensure_schema_exists(cat, sch)\n",
    "        # Выполняем cleaned DDL\n",
    "        cursor.execute(cleaned)\n",
    "        print(\"Executed cleaned DDL (WITH removed).\")\n",
    "        continue\n",
    "    except Exception as e2:\n",
    "        msg2 = str(e2)\n",
    "        print(\"Cleaned DDL also failed:\", msg2)\n",
    "\n",
    "        # Если ошибка говорит, что Schema X not found — попробуем создать схему и повторить\n",
    "        if \"Schema\" in msg2 and \"not found\" in msg2:\n",
    "            # Попробуем извлечь нужный catalog/schema из первоначальной строки\n",
    "            m = _create_table_re.search(cleaned)\n",
    "            if m:\n",
    "                fq = m.group(1)\n",
    "                cat, sch, tbl = parse_fq_name(fq)\n",
    "                if not cat:\n",
    "                    cat = 'flights'  # если не указан, используем flights, но подставь нужный\n",
    "                if sch:\n",
    "                    print(f\"Attempting to create missing schema {cat}.{sch} and retry...\")\n",
    "                    try:\n",
    "                        ensure_schema_exists(cat, sch)\n",
    "                        # повторная попытка\n",
    "                        cursor.execute(cleaned)\n",
    "                        print(\"Executed cleaned DDL after creating schema.\")\n",
    "                        continue\n",
    "                    except Exception as e3:\n",
    "                        print(\"Retry after schema creation failed:\", e3)\n",
    "        # Иначе — печатаем финальную ошибку\n",
    "        print(\"Failed to apply DDL. See above errors for details.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf64fb-d4d2-422b-b1b1-fd06f25dbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl[\"statement\"].rstrip(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791406f-0ffd-415a-a5f9-e780467a5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(ddl_statement)\n",
    "print(\"Table created in Trino!\")(ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580d7f5-bff0-476e-b82f-4839e8cbd36a",
   "metadata": {},
   "source": [
    "## Проверка созданных таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670227a-f16b-4526-8339-00dcc32dc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SHOW TABLES;\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0deecd-d049-4260-bd77-69255f84f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем таблицы случайными данными (имитация)\n",
    "for ddl in task_input.get(\"ddl\", []):\n",
    "    table_name = ddl[\"statement\"].split()[2]  # простая попытка извлечь имя таблицы\n",
    "    try:\n",
    "        # получаем кол-во столбцов\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = [col[1] for col in cursor.fetchall()]\n",
    "        for _ in range(100):  # 100 строк на таблицу\n",
    "            values = [random.randint(1, 1000) if col.lower() != 'id' else _ for col in columns]\n",
    "            placeholders = \",\".join([\"?\"]*len(values))\n",
    "            cursor.execute(f\"INSERT INTO {table_name} ({','.join(columns)}) VALUES ({placeholders})\", values)\n",
    "    except Exception as e:\n",
    "        print(\"Insert error:\", e)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18875893-3a55-4c21-9296-ed889569dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query_real(query, frequency=1, timeout=600):\n",
    "    \"\"\"Прогоняем запрос и замеряем время выполнения\"\"\"\n",
    "    try:\n",
    "        start = time.time()\n",
    "        cursor.execute(query)\n",
    "        cursor.fetchall()  # получаем результат\n",
    "        duration = time.time() - start\n",
    "        if duration > timeout:\n",
    "            duration = timeout\n",
    "    except Exception:\n",
    "        duration = timeout\n",
    "    \n",
    "    # ресурсы (для SQLite синтетически)\n",
    "    resources_used = random.randint(50, 200)  # MB\n",
    "    return {\n",
    "        \"queryid\": query[:8],\n",
    "        \"frequency\": frequency,\n",
    "        \"time_before\": duration,\n",
    "        \"time_after\": duration,\n",
    "        \"resources_before\": resources_used,\n",
    "        \"resources_after\": resources_used\n",
    "    }\n",
    "\n",
    "# Прогон всех запросов\n",
    "before_metrics = [run_query_real(q[\"query\"], q.get(\"runquantity\", 1)) for q in task_input.get(\"queries\", [])]\n",
    "print(\"Before metrics:\", before_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bf6a5-d484-4b77-9ed6-b1a87eab3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "# api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# client = OpenAI(api_key=api_key)\n",
    "# async_client = AsyncOpenAI(\n",
    "#     api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "#     http_client=httpx.AsyncClient(proxies=\"socks5://localhost:1080\")\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "async_client = AsyncOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPEN_ROUTER\"),\n",
    "    http_client=httpx.AsyncClient(proxies=\"socks5://localhost:1080\")\n",
    ")\n",
    "\n",
    "        model=\"google/gemma-3n-e2b-it:free\",\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a database analyst. \n",
    "Your task is to analyze the logical data model, data statistics, \n",
    "as well as the structure and statistics of SQL queries.\n",
    "Provide recommendations for modifying the data structure and queries \n",
    "to optimize performance.\n",
    "Respond with a JSON object containing the following fields:\n",
    "- ddl: a new set of DDL statements to modify the table structure\n",
    "- migrations: a set of queries for migrating data\n",
    "- queries: a set of queries with their identifiers that use the new table structure\n",
    "\"\"\"\n",
    "\n",
    "async def analyze_task(task_input):\n",
    "    response = await async_client.chat.completions.create(\n",
    "        # model=\"gpt-4o-mini\",\n",
    "        model=\"google/gemma-3n-e2b-it:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(task_input)},\n",
    "        ],\n",
    "        extra_headers={\"Authorization\": f\"Bearer {os.getenv('OPEN_ROUTER')}\"}\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# Получаем рекомендации LLM\n",
    "llm_result = await analyze_task(task_input)\n",
    "llm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102fff3-349a-4f52-a222-a9617de8e030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1e4b2-19f8-4b0b-94c0-044909078942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd02cb-7932-4a0c-acf6-d0040e2f8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем новый DDL\n",
    "for ddl in llm_result.get(\"ddl\", []):\n",
    "    try:\n",
    "        cursor.execute(ddl[\"statement\"])\n",
    "    except Exception as e:\n",
    "        print(\"DDL error after LLM:\", e)\n",
    "conn.commit()\n",
    "\n",
    "# Применяем миграции\n",
    "for mig in llm_result.get(\"migrations\", []):\n",
    "    try:\n",
    "        cursor.execute(mig[\"statement\"])\n",
    "    except Exception as e:\n",
    "        print(\"Migration error:\", e)\n",
    "conn.commit()\n",
    "\n",
    "# Замер после оптимизации\n",
    "after_metrics = []\n",
    "for q in llm_result.get(\"queries\", []):\n",
    "    metrics = run_query_real(q[\"query\"], frequency=1)\n",
    "    after_metrics.append(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734f2ee-a634-4fc8-9875-e8a440d2546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_x(operations):\n",
    "    numerator = sum(op[\"frequency\"] * op[\"time_before\"] for op in operations)\n",
    "    denominator = sum(op[\"frequency\"] * op[\"time_after\"] for op in operations)\n",
    "    return numerator / denominator if denominator else float('inf')\n",
    "\n",
    "def compute_y(operations):\n",
    "    S = sum(op[\"resources_before\"] for op in operations)\n",
    "    C = sum(op[\"resources_after\"] for op in operations)\n",
    "    return S / C if C else float('inf')\n",
    "\n",
    "def compute_z(operations):\n",
    "    x = compute_x(operations)\n",
    "    y = compute_y(operations)\n",
    "    return x * y ** (1/3)\n",
    "\n",
    "# Объединяем метрики для расчёта\n",
    "for b, a in zip(before_metrics, after_metrics):\n",
    "    b[\"time_after\"] = a[\"time_after\"]\n",
    "    b[\"resources_after\"] = a[\"resources_after\"]\n",
    "\n",
    "z = compute_z(before_metrics)\n",
    "print(\"Overall score z:\", z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62edcdff-3261-4f5c-9e26-0e7412ce3826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88720cb0-f127-4ece-995e-22bf65650f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea430e-29b5-4775-9b83-d3c8fac54f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
