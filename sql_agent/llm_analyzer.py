"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ë–î —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM
"""

import json
import logging
from typing import Dict, Any, Optional
from openai import OpenAI
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

logger = logging.getLogger(__name__)


class LLMAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ë–î —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM"""
    
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            api_key: API –∫–ª—é—á –¥–ª—è OpenRouter (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –±–µ—Ä–µ—Ç—Å—è –∏–∑ OPEN_ROUTER)
            base_url: –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è API (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é OpenRouter)
        """
        self.api_key = api_key or os.getenv("OPEN_ROUTER")
        self.base_url = base_url or "https://openrouter.ai/api/v1"
        
        if not self.api_key:
            raise ValueError("API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPEN_ROUTER –≤ .env —Ñ–∞–π–ª–µ")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç
        self.client = OpenAI(
            base_url=self.base_url,
            api_key=self.api_key,
        )
        
        # –ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_model = "google/gemini-2.5-flash-preview-09-2025"
        
        # –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏)
        self.evaluation_model = "google/gemini-2.5-flash-preview-09-2025"
        
        logger.info(f"LLM Analyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é: {self.analysis_model}")
    
    def analyze_database(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            request_data: –î–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞ —Å DDL, queries –∏ URL
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            system_prompt = self._get_analysis_prompt()
            user_input = json.dumps(request_data, ensure_ascii=False, indent=2)
            
            logger.info("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ë–î")
            logger.info(f"üì§ –ó–ê–ü–†–û–° –ö LLM (–º–æ–¥–µ–ª—å: {self.analysis_model}):")
            logger.info(f"System prompt: {system_prompt[:200]}...")
            logger.info(f"User input: {user_input[:500]}...")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            response = self.client.chat.completions.create(
                model=self.analysis_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                max_tokens=4000,
                extra_headers={
                    "HTTP-Referer": "http://localhost",
                    "X-Title": "SQL Agent Analysis"
                }
            )
            
            llm_output = response.choices[0].message.content
            logger.info("–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM")
            logger.info(f"üì• –û–¢–í–ï–¢ –û–¢ LLM:")
            logger.info(f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç: {llm_output}")
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            try:
                result = json.loads(llm_output)
                logger.info("JSON –æ—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω")
                return result
            except json.JSONDecodeError as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç")
                # –ï—Å–ª–∏ JSON –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
                return self._create_fallback_result(llm_output, request_data)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ë–î: {str(e)}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._create_fallback_result("", request_data)
    
    def evaluate_response(self, task_input: str, output: str) -> int:
        """
        –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞ LLM –ø–æ 10-–±–∞–ª–ª—å–Ω–æ–π —à–∫–∞–ª–µ
        
        Args:
            task_input: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
            output: –û—Ç–≤–µ—Ç LLM
            
        Returns:
            –û—Ü–µ–Ω–∫–∞ –æ—Ç 1 –¥–æ 10
        """
        try:
            prompt = f"""You are an evaluator of LLM responses. 
            Evaluate the response strictly on a 10-point scale (1 = worst, 10 = best), based on correctness and completeness.
            
            The LLM receives the following input:
            - DDL statements for creating tables. The script is split into individual queries for each table.
            - A set of queries with statistics on how many times each query was executed.
            - A JDBC connection string with login and password to evaluate the actual data.
            
            The LLM output includes:
            - A new set of DDL queries to modify the table structure.
            - A set of queries for data migration.
            - A set of queries with identifiers that use the new table structure.
            
            Your task: **return only a single integer from 1 to 10** that represents the overall quality of the LLM response. Do not include any explanation, text, or punctuation.
            
            Input: {task_input}
            LLM Response: {output}
            """
            
            logger.info(f"üì§ –ó–ê–ü–†–û–° –ö –ú–û–î–ï–õ–ò –û–¶–ï–ù–ö–ò (–º–æ–¥–µ–ª—å: {self.evaluation_model}):")
            logger.info(f"–ü—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {prompt[:300]}...")
            
            response = self.client.chat.completions.create(
                model=self.evaluation_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=10,
                extra_headers={
                    "HTTP-Referer": "http://localhost",
                    "X-Title": "SQL Agent Evaluation"
                }
            )
            
            score_text = response.choices[0].message.content.strip()
            logger.info(f"üì• –û–¢–í–ï–¢ –û–¢ –ú–û–î–ï–õ–ò –û–¶–ï–ù–ö–ò:")
            logger.info(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: '{score_text}'")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
            try:
                score = int(score_text)
                if 1 <= score <= 10:
                    logger.info(f"‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {score}/10")
                    return score
                else:
                    logger.warning(f"–û—Ü–µ–Ω–∫–∞ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 1-10: {score}")
                    logger.info(f"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5/10")
                    return 5  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            except ValueError:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤—É—é –æ—Ü–µ–Ω–∫—É: {score_text}")
                logger.info(f"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5/10")
                return 5  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
            return 5  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _get_analysis_prompt(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ë–î"""
        return """You are a database analyst and optimization expert. 
Your task is to analyze the logical data model, data statistics, 
as well as the structure and statistics of SQL queries.
Provide recommendations for modifying the data structure and queries 
to optimize performance.

Analyze the provided data and respond with a JSON object containing the following fields:
- ddl: a new set of DDL statements to modify the table structure (array of objects with "statement" field)
- migrations: a set of queries for migrating data (array of objects with "statement" field)  
- queries: a set of queries with their identifiers that use the new table structure (array of objects with "queryid", "query", "runquantity" fields)

Focus on:
1. Index optimization based on query patterns
2. Table partitioning strategies
3. Data type optimization
4. Query rewriting for better performance
5. Schema normalization/denormalization where appropriate

Return only valid JSON without any additional text or explanations."""

    def _create_fallback_result(self, llm_output: str, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
        
        Args:
            llm_output: –°—ã—Ä–æ–π –≤—ã–≤–æ–¥ LLM
            request_data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ URL
        url = request_data.get("url", "jdbc:trino://localhost:8080")
        catalog_name = self._extract_catalog_from_url(url)
        
        # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        ddl = [
            {"statement": f"CREATE SCHEMA IF NOT EXISTS {catalog_name}.optimized_schema"},
            {"statement": f"CREATE TABLE {catalog_name}.optimized_schema.optimized_table (id INTEGER, data TEXT)"}
        ]
        
        migrations = [
            {"statement": f"INSERT INTO {catalog_name}.optimized_schema.optimized_table SELECT 1, 'optimized_data'"}
        ]
        
        queries = []
        for query_data in request_data.get("queries", []):
            queries.append({
                "queryid": query_data.get("queryid", "optimized_query"),
                "query": f"SELECT * FROM {catalog_name}.optimized_schema.optimized_table WHERE id = 1",
                "runquantity": query_data.get("runquantity", 1)
            })
        
        return {
            "ddl": ddl,
            "migrations": migrations,
            "queries": queries,
            "note": "Fallback result due to parsing error",
            "raw_output": llm_output[:500] if llm_output else ""
        }
    
    def _extract_catalog_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –∫–∞—Ç–∞–ª–æ–≥–∞ –∏–∑ JDBC URL"""
        try:
            if 'jdbc://' in url:
                url_part = url.replace('jdbc://', '')
                if '/' in url_part:
                    db_part = url_part.split('/')[-1]
                    if '?' in db_part:
                        db_name = db_part.split('?')[0]
                    else:
                        db_name = db_part
                    return db_name if db_name else "default_catalog"
            return "default_catalog"
        except:
            return "default_catalog"
